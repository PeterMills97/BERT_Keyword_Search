{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "24fe6ebd-de01-4767-b335-3e84cf0197a3",
   "metadata": {},
   "source": [
    "# Keyword Searching using BERT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0597e828",
   "metadata": {},
   "source": [
    "The pirpose of this notebook is to use the BERT NLP framework to build a keyword search engine for the review section of the running shoe reviews. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5b39b396-e57e-4388-8232-ba8b6af3e7cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from transformers import BertTokenizer, BertModel\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import time\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e1f1ee28-1c06-415e-b680-f5e30b150fb9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>link</th>\n",
       "      <th>page</th>\n",
       "      <th>date</th>\n",
       "      <th>headline</th>\n",
       "      <th>description</th>\n",
       "      <th>review_body</th>\n",
       "      <th>comments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://www.runningshoesguru.com/2017/09/hoka-...</td>\n",
       "      <td>[b', html, \\n \\n, [ \\n, [\\n, &lt;link as=\"style\" ...</td>\n",
       "      <td>2017-09-28T09:49:35-04:00</td>\n",
       "      <td>Hoka One One Stinson ATR 4</td>\n",
       "      <td>The Stinson ATR 4 is built for long days on th...</td>\n",
       "      <td>The Stinson ATR 4 is the newest version of th...</td>\n",
       "      <td>[The bondi 5’s are like boards now-so stiff an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://www.runningshoesguru.com/2015/08/nike-...</td>\n",
       "      <td>[b', html, \\n \\n, [ \\n, [\\n, &lt;link as=\"style\" ...</td>\n",
       "      <td>2017-11-25T13:13:48-05:00</td>\n",
       "      <td>Nike Free Flyknit 4.0</td>\n",
       "      <td>It\\xe2\\x80\\x99s hard to believe that the Nike ...</td>\n",
       "      <td>Nike Free Flyknit 4.0 General Info: The Free ...</td>\n",
       "      <td>[Is this shoe recommended for marathons? Pls s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://www.runningshoesguru.com/2018/08/new-b...</td>\n",
       "      <td>[b', html, \\n \\n, [ \\n, [\\n, &lt;link as=\"style\" ...</td>\n",
       "      <td>2018-08-15T08:54:42-04:00</td>\n",
       "      <td>New Balance Fresh Foam Beacon</td>\n",
       "      <td>The New Balance Fresh Foam Beacon is a lightwe...</td>\n",
       "      <td>Light, Airy, Comfortable, Responsive, Flexibl...</td>\n",
       "      <td>[I have 60 miles on my Beacons and I can’t pra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://www.runningshoesguru.com/2012/09/scott...</td>\n",
       "      <td>[b', html, \\n \\n, [ \\n, [\\n, &lt;link as=\"style\" ...</td>\n",
       "      <td>2012-09-28T18:38:48-04:00</td>\n",
       "      <td>Scott T2C</td>\n",
       "      <td>The Scott T2C provides an eminently enjoyable ...</td>\n",
       "      <td>Scott T2C General info The T2C is a lightweig...</td>\n",
       "      <td>[I love mine and wish I could still buy them s...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                link  \\\n",
       "0  https://www.runningshoesguru.com/2017/09/hoka-...   \n",
       "1  https://www.runningshoesguru.com/2015/08/nike-...   \n",
       "2  https://www.runningshoesguru.com/2018/08/new-b...   \n",
       "3  https://www.runningshoesguru.com/2012/09/scott...   \n",
       "\n",
       "                                                page  \\\n",
       "0  [b', html, \\n \\n, [ \\n, [\\n, <link as=\"style\" ...   \n",
       "1  [b', html, \\n \\n, [ \\n, [\\n, <link as=\"style\" ...   \n",
       "2  [b', html, \\n \\n, [ \\n, [\\n, <link as=\"style\" ...   \n",
       "3  [b', html, \\n \\n, [ \\n, [\\n, <link as=\"style\" ...   \n",
       "\n",
       "                        date                       headline  \\\n",
       "0  2017-09-28T09:49:35-04:00     Hoka One One Stinson ATR 4   \n",
       "1  2017-11-25T13:13:48-05:00          Nike Free Flyknit 4.0   \n",
       "2  2018-08-15T08:54:42-04:00  New Balance Fresh Foam Beacon   \n",
       "3  2012-09-28T18:38:48-04:00                      Scott T2C   \n",
       "\n",
       "                                         description  \\\n",
       "0  The Stinson ATR 4 is built for long days on th...   \n",
       "1  It\\xe2\\x80\\x99s hard to believe that the Nike ...   \n",
       "2  The New Balance Fresh Foam Beacon is a lightwe...   \n",
       "3  The Scott T2C provides an eminently enjoyable ...   \n",
       "\n",
       "                                         review_body  \\\n",
       "0   The Stinson ATR 4 is the newest version of th...   \n",
       "1   Nike Free Flyknit 4.0 General Info: The Free ...   \n",
       "2   Light, Airy, Comfortable, Responsive, Flexibl...   \n",
       "3   Scott T2C General info The T2C is a lightweig...   \n",
       "\n",
       "                                            comments  \n",
       "0  [The bondi 5’s are like boards now-so stiff an...  \n",
       "1  [Is this shoe recommended for marathons? Pls s...  \n",
       "2  [I have 60 miles on my Beacons and I can’t pra...  \n",
       "3  [I love mine and wish I could still buy them s...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review_data=pd.read_pickle('Processed_dataset.pkl')\n",
    "review_data.head(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c58e1511-52d2-40fc-9179-b931954ff60e",
   "metadata": {},
   "source": [
    "## Linear algeba helper functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2adaa348",
   "metadata": {},
   "source": [
    "Once we have encoded our articles, we will want to use an inner product to compare them, these functions simplify this. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4e809b6a-ac46-4d0c-843b-630019ca6223",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalise(vect):\n",
    "    if np.linalg.norm(vect)!=0:\n",
    "        return vect/np.linalg.norm(vect)\n",
    "    else:\n",
    "        return vect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3f808d5a-453b-4966-980c-b21fc69858b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def similarity(vect1,vect2):\n",
    "    return np.inner(normalise(vect1),normalise(vect2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1941b03-4e9f-4bf9-a4dc-94a13eb69763",
   "metadata": {},
   "source": [
    "## Load Bert Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fced08a",
   "metadata": {},
   "source": [
    "Load the Bert model with hidden states, whcih we will use as the basis for the encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8f4f4d35-ef11-4f9f-9a23-46fab42a0953",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertModel(\n",
       "  (embeddings): BertEmbeddings(\n",
       "    (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "    (position_embeddings): Embedding(512, 768)\n",
       "    (token_type_embeddings): Embedding(2, 768)\n",
       "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (encoder): BertEncoder(\n",
       "    (layer): ModuleList(\n",
       "      (0-11): 12 x BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pooler): BertPooler(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (activation): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert_model= BertModel.from_pretrained('bert-base-uncased',\n",
    "                                  output_hidden_states = True, # We need all hidden states for our encoding\n",
    "                                  )\n",
    "bert_model = bert_model.to('cuda')\n",
    "bert_model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "049ac9a7-6175-4611-83d6-56daec2f14f8",
   "metadata": {},
   "source": [
    "## Encode a sentence "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe73eaf3",
   "metadata": {},
   "source": [
    "To encode a stennce the steps are as follows: \n",
    "\n",
    "1) Add special tokens and tokanise the text\n",
    "2) Create a segment to tell the model everything is one sentence (Bert is trained on 2 sentences)\n",
    "3) Feed tokens and segments to the model ('cuda' is set so GPU is used)\n",
    "4) Use PyTorch to stack all 12 hidden states to create our embedding for the whole sentence \n",
    "5) Create a list of embeddigns for each word using 4 of the hidden states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7a3b1326-af6d-4d3c-904a-8b60d9b5a185",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_sentence(sentence,model,tokenizer=BertTokenizer.from_pretrained('bert-base-uncased')):\n",
    "    #add end tokens \n",
    "    sentence = \"[CLS] \" + sentence + \" [SEP]\"\n",
    "    #tokenize text \n",
    "    tokenized_text = tokenizer.tokenize(sentence)\n",
    "    #covert to indecies \n",
    "    indexed_tokens = tokenizer.convert_tokens_to_ids(tokenized_text)\n",
    "    #create segment index (all 1's)\n",
    "    segments_ids = [1] * len(tokenized_text)\n",
    "    #convert to tensors\n",
    "    tokens_tensor = torch.tensor([indexed_tokens])\n",
    "    segments_tensors = torch.tensor([segments_ids])\n",
    "\n",
    "    #get output from model\n",
    "    output_states=model(tokens_tensor.to('cuda'), segments_tensors.to('cuda'))[2]\n",
    "    #stack all hidden layers\n",
    "    token_embeddings = torch.stack(output_states, dim=0)\n",
    "    token_embeddings = torch.squeeze(token_embeddings, dim=1)\n",
    "    token_embeddings = token_embeddings.permute(1,0,2)\n",
    "\n",
    "    token_vecs_cat = []\n",
    "\n",
    "    \n",
    "\n",
    "    # For each token in the sentence...\n",
    "    for token in token_embeddings:\n",
    "    \n",
    "    # `token` is a [12 x 768] tensor\n",
    "\n",
    "        # Concatenate the vectors (that is, append them together) from the last \n",
    "        # four layers.\n",
    "        # Each layer vector is 768 values, so `cat_vec` is length 3,072.\n",
    "        cat_vec = torch.cat((token[-1], token[-2], token[-3], token[-4]), dim=0)\n",
    "        #convert to numpy \n",
    "        cat_vec=cat_vec.cpu()\n",
    "        cat_vec=cat_vec.detach().numpy()\n",
    "    \n",
    "        # Use `cat_vec` to represent `token`.\n",
    "        token_vecs_cat.append(cat_vec)\n",
    "    #get rid of blank tokens    \n",
    "    token_vecs_cat=token_vecs_cat[1:-1]\n",
    "    \n",
    "    return token_vecs_cat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "995eae12",
   "metadata": {},
   "source": [
    "## Test: Encode sentence "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f242f3f9",
   "metadata": {},
   "source": [
    "Here we test that the function is returning a list of numpy arrays with dimension 3072"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "beb5b49b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def unit_test1(sentence, model=bert_model):\n",
    "    start = time.time()\n",
    "    test_case=encode_sentence(sentence, model)\n",
    "    end= time.time()\n",
    "    print('Return type:', type(test_case))\n",
    "    if type(test_case)==list:\n",
    "        print('Element type:', type(test_case[0]))\n",
    "    print('Return shape:',np.shape(test_case))\n",
    "    print('Run time for encoding:',end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6a043166",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test case: This is a test sentence\n",
      "Return type: <class 'list'>\n",
      "Element type: <class 'numpy.ndarray'>\n",
      "Return shape: (5, 3072)\n",
      "Run time for encoding: 0.5337522029876709\n",
      "\n",
      "Test case: This is a much longer test sentance, containing the word antidisestablishmentarianism\n",
      "Return type: <class 'list'>\n",
      "Element type: <class 'numpy.ndarray'>\n",
      "Return shape: (20, 3072)\n",
      "Run time for encoding: 0.026926040649414062\n",
      "\n",
      "Test case: antidisestablishmentarianism\n",
      "Return type: <class 'list'>\n",
      "Element type: <class 'numpy.ndarray'>\n",
      "Return shape: (8, 3072)\n",
      "Run time for encoding: 0.02094864845275879\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_cases=['This is a test sentence','This is a much longer test sentance, containing the word antidisestablishmentarianism',\n",
    "           'antidisestablishmentarianism']\n",
    "\n",
    "for case in test_cases:\n",
    "    print('Test case:', case)\n",
    "    unit_test1(case)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a1607c6",
   "metadata": {},
   "source": [
    "We can see that not all words are encoded as a single token, this is not an issue merely how Bert tokenises text."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e81286b3-3be2-4c0b-bbe0-31c69a8150e1",
   "metadata": {},
   "source": [
    "## Encode an Article "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb9dc7fe",
   "metadata": {},
   "source": [
    "Now we are in need of a function to encode whole articles. This is pretty simple, we are going to split an article into sentences and encode those and sum them, using numpy. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6caaf9c4-7f50-4361-9311-0abe3b9e9dfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def article_encode(review_text,model):\n",
    "    review_df=pd.Series(review_text.strip().split('.'))\n",
    "    review_df=review_df.apply(lambda x: encode_sentence(x,model))\n",
    "    return review_df.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c20007f5",
   "metadata": {},
   "source": [
    "## Test: Encode an Article "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9946e373",
   "metadata": {},
   "outputs": [],
   "source": [
    "def unit_test2(article):\n",
    "    start = time.time()\n",
    "    article_encoded=article_encode(article,bert_model)\n",
    "    end= time.time()\n",
    "    \n",
    "    print('Number of sentences in encoding:',len(article_encoded))\n",
    "    print('Run time:', end-start)\n",
    "    print('Total floats stored:', np.shape(article_encoded[0])[0]*len(article_encoded))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "14e0afba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get first 5 example reviews\n",
    "\n",
    "example_reviews=review_data['review_body'][0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "50e3e365",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "words in review: 1253\n",
      "Number of sentences in encoding: 1483\n",
      "Run time: 0.7297601699829102\n",
      "Total floats stored: 4555776\n",
      "\n",
      "words in review: 934\n",
      "Number of sentences in encoding: 1187\n",
      "Run time: 0.7282774448394775\n",
      "Total floats stored: 3646464\n",
      "\n",
      "words in review: 1025\n",
      "Number of sentences in encoding: 1242\n",
      "Run time: 0.5659785270690918\n",
      "Total floats stored: 3815424\n",
      "\n",
      "words in review: 526\n",
      "Number of sentences in encoding: 721\n",
      "Run time: 0.2979886531829834\n",
      "Total floats stored: 2214912\n",
      "\n",
      "words in review: 941\n",
      "Number of sentences in encoding: 1090\n",
      "Run time: 0.556598424911499\n",
      "Total floats stored: 3348480\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for review in example_reviews:\n",
    "    print('words in review:', len(review.split()))\n",
    "    unit_test2(review)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0406034e-c39f-41f9-bc17-5308b1e8c652",
   "metadata": {},
   "source": [
    "## Tokenise an article "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51bd6611-e18f-4ade-8eb1-57dddd075871",
   "metadata": {},
   "source": [
    "We could have added the tokenisation as a return from our encoding function, but this would have required unnessesary computation when tokenisation is needed on it's own. Mirroring the previous sections, we'll write functions to tokenise a single sentence and then apply this to a whole article."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6fccb82c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence_tokenize(sentence,tokenizer=BertTokenizer.from_pretrained('bert-base-uncased')):\n",
    "    sentence = \"[CLS] \" + sentence + \" [SEP]\"\n",
    "    tokenized_text = tokenizer.tokenize(sentence)\n",
    "    tokenized_text=tokenized_text[1:-1]\n",
    "    return tokenized_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c483eaed-7148-4bbc-b7b9-d2ec6ce56e97",
   "metadata": {},
   "outputs": [],
   "source": [
    "def article_tokenizer(review_text,tokenizer=BertTokenizer.from_pretrained('bert-base-uncased')):\n",
    "    review_df=pd.Series(review_text.strip().split('.'))\n",
    "    review_df=review_df.apply(lambda x: sentence_tokenize(x))\n",
    "    return review_df.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ccf8a49",
   "metadata": {},
   "source": [
    "## Test: Tokenise an article "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc1087f3",
   "metadata": {},
   "source": [
    "The key thing we need to check here is that the tokenisation is always producing the same length result as the encoder "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2de6bf91",
   "metadata": {},
   "outputs": [],
   "source": [
    "def unit_test3(article):\n",
    "    start = time.time()\n",
    "    article_tokenised=article_tokenizer(article)\n",
    "    end= time.time()\n",
    "    \n",
    "    article_encoded=article_encode(article,bert_model)\n",
    "    if len(article_tokenised)==len(article_encoded):\n",
    "        print('Lengths match!')\n",
    "    else:\n",
    "        print('Lengths do NOT match!')\n",
    "        \n",
    "    print('number of tokens:',len(article_tokenised))\n",
    "    print('number of encodings:',len(article_encoded))\n",
    "    print('Run time:', end-start)\n",
    "    print()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4b40cd04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "words in review: 1253\n",
      "Lengths match!\n",
      "number of tokens: 1483\n",
      "number of encodings: 1483\n",
      "Run time: 0.015005350112915039\n",
      "\n",
      "\n",
      "words in review: 934\n",
      "Lengths match!\n",
      "number of tokens: 1187\n",
      "number of encodings: 1187\n",
      "Run time: 0.015999555587768555\n",
      "\n",
      "\n",
      "words in review: 1025\n",
      "Lengths match!\n",
      "number of tokens: 1242\n",
      "number of encodings: 1242\n",
      "Run time: 0.01100015640258789\n",
      "\n",
      "\n",
      "words in review: 526\n",
      "Lengths match!\n",
      "number of tokens: 721\n",
      "number of encodings: 721\n",
      "Run time: 0.016201019287109375\n",
      "\n",
      "\n",
      "words in review: 941\n",
      "Lengths match!\n",
      "number of tokens: 1090\n",
      "number of encodings: 1090\n",
      "Run time: 0.010125398635864258\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "example_reviews=review_data['review_body'][0:5]\n",
    "\n",
    "for review in example_reviews:\n",
    "    print('words in review:', len(review.split()))\n",
    "    unit_test3(review)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73f14859-c827-4c9e-b590-44fbf717445a",
   "metadata": {},
   "source": [
    "## Encode all the articles "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "367d6fa9-5d4d-4a60-a2a7-f94f427efe56",
   "metadata": {},
   "source": [
    "The plan here is to apply the article_encoder and the article_tokeniser functions to every article in the dataset. The end result will be a new column containing lists with the tokens and encodings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "00253490-efaf-4146-8a97-70593e329e47",
   "metadata": {},
   "outputs": [],
   "source": [
    "def article_create_encoding(review_text,model):\n",
    "    \n",
    "    article_encoding=article_encode(review_text,model)\n",
    "    article_tokens=article_tokenizer(review_text)\n",
    "    \n",
    "    return [article_tokens, article_encoding] \n",
    "\n",
    "#this is not an ideal way to store this information but it does allow for easy comparison of tokens and encodings "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6a91253-ccd3-4bdf-a552-c828007d27a7",
   "metadata": {},
   "source": [
    "Running the encoding on all articles takes 8.5 minutes to run on my laptops GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9cfd2ab8-ffd7-4ba4-9305-08b86d4a45b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "                                                link  \\\n",
      "0  https://www.runningshoesguru.com/2017/09/hoka-...   \n",
      "1  https://www.runningshoesguru.com/2015/08/nike-...   \n",
      "2  https://www.runningshoesguru.com/2018/08/new-b...   \n",
      "3  https://www.runningshoesguru.com/2012/09/scott...   \n",
      "\n",
      "                                                page  \\\n",
      "0  [b', html, \\n \\n, [ \\n, [\\n, <link as=\"style\" ...   \n",
      "1  [b', html, \\n \\n, [ \\n, [\\n, <link as=\"style\" ...   \n",
      "2  [b', html, \\n \\n, [ \\n, [\\n, <link as=\"style\" ...   \n",
      "3  [b', html, \\n \\n, [ \\n, [\\n, <link as=\"style\" ...   \n",
      "\n",
      "                        date                       headline  \\\n",
      "0  2017-09-28T09:49:35-04:00     Hoka One One Stinson ATR 4   \n",
      "1  2017-11-25T13:13:48-05:00          Nike Free Flyknit 4.0   \n",
      "2  2018-08-15T08:54:42-04:00  New Balance Fresh Foam Beacon   \n",
      "3  2012-09-28T18:38:48-04:00                      Scott T2C   \n",
      "\n",
      "                                         description  \\\n",
      "0  The Stinson ATR 4 is built for long days on th...   \n",
      "1  It\\xe2\\x80\\x99s hard to believe that the Nike ...   \n",
      "2  The New Balance Fresh Foam Beacon is a lightwe...   \n",
      "3  The Scott T2C provides an eminently enjoyable ...   \n",
      "\n",
      "                                         review_body  \\\n",
      "0   The Stinson ATR 4 is the newest version of th...   \n",
      "1   Nike Free Flyknit 4.0 General Info: The Free ...   \n",
      "2   Light, Airy, Comfortable, Responsive, Flexibl...   \n",
      "3   Scott T2C General info The T2C is a lightweig...   \n",
      "\n",
      "                                            comments  \n",
      "0  [The bondi 5’s are like boards now-so stiff an...  \n",
      "1  [Is this shoe recommended for marathons? Pls s...  \n",
      "2  [I have 60 miles on my Beacons and I can’t pra...  \n",
      "3  [I love mine and wish I could still buy them s...  \n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "#review_data['encoded_review_body']=review_data['review_body'].apply(lambda x: article_create_encoding(x,bert_model))\n",
    "end= time.time()\n",
    "print((end-start)/60)\n",
    "print(review_data.head(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1464cf9f-c3c5-4f43-b09f-371c5504c347",
   "metadata": {},
   "outputs": [],
   "source": [
    "#review_data.to_pickle('Review_data_BERT.pkl')\n",
    "\n",
    "review_data=pd.read_pickle('Review_data_BERT.pkl')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b76a0e7c-3846-4382-81c0-901a20a4a9e1",
   "metadata": {},
   "source": [
    "## Clear stopwords for each article "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5354aad",
   "metadata": {},
   "source": [
    "When search for keywords we really are not interested in matching with stop words, so remove this issue let's simply remove them from the articles before searching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5d7e92b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clear_stopwords(encoded_article):\n",
    "    tokens=encoded_article[0]\n",
    "    vectors=encoded_article[1]\n",
    "    \n",
    "    cleared_tokens=[]\n",
    "    cleared_vectors=[]\n",
    "    \n",
    "    if len(tokens)!=len(vectors):\n",
    "        return 'tokens and vector lengths dont match'\n",
    "    \n",
    "    for i in range(len(tokens)):\n",
    "        if tokens[i] not in stopwords.words('english') and len(tokens[i])>1:\n",
    "            cleared_tokens+=[tokens[i]]\n",
    "            cleared_vectors+=[vectors[i]]\n",
    "        \n",
    "    \n",
    "    return [cleared_tokens,cleared_vectors]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "18cb9ecf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.5759114066759747\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "review_data['encoded_review_body']=review_data['encoded_review_body'].apply(lambda x: clear_stopwords(x))\n",
    "end= time.time()\n",
    "print((end-start)/60)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7c1bfa6",
   "metadata": {},
   "source": [
    "## Article keyword count"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccd2304c",
   "metadata": {},
   "source": [
    "This section contains two functions. Keyword_count, this uses a fixed sentence to help encode our keyword. I found this to be a much more powerful method than encoding just the word on it's own. I chose the sentence \"look for --- in the text\" but to refine the algorithm it might be advantageuous to experiment with this. \n",
    "\n",
    "The second function counts the instances of similar words in an article. I set the threshiold for this as a similarity of 0.5 or greater, this is another parameter that could be tuned. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4da9f18f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def keyword_encode(keyword):\n",
    "    keyword.strip()\n",
    "    key_sentence='look for '+keyword+' in the text'\n",
    "    \n",
    "    return encode_sentence(key_sentence,bert_model)[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0c1240b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "keyword: the vector for our chosen keyword \n",
    "\n",
    "encoded_article: entry in the pandas \n",
    "\n",
    "'''\n",
    "\n",
    "def article_keyword_count(keyword, encoded_article, threshold=0.5):\n",
    "    article_df=pd.DataFrame(encoded_article[0], columns=['tokens'])\n",
    "    article_df['encoding']=pd.Series(encoded_article[1])\n",
    "    \n",
    "    article_df['similarity']=article_df['encoding'].apply(lambda x: similarity(x,keyword))\n",
    "    article_df=article_df[article_df['similarity']>=threshold]\n",
    "    #print(article_df.index)\n",
    "    return np.shape(article_df)[0], article_df['tokens']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b557c49a",
   "metadata": {},
   "source": [
    "## Test: article keyword count "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c7c6e8d",
   "metadata": {},
   "source": [
    "The test for the keyword encoding is just there to check that the output is a numpy array with the correct dimension and that the time taken is reasonable "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6332fdff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def unit_test4(keyword):\n",
    "    start = time.time()\n",
    "    test_encoding=keyword_encode(keyword)\n",
    "    end= time.time()\n",
    "    print('Type of return',type(test_encoding))\n",
    "    print('Shape of return',np.shape(test_encoding))\n",
    "    print('Run time:',end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2efd70ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "race\n",
      "Type of return <class 'numpy.ndarray'>\n",
      "Shape of return (3072,)\n",
      "Run time: 0.1623682975769043\n",
      "\n",
      "trail\n",
      "Type of return <class 'numpy.ndarray'>\n",
      "Shape of return (3072,)\n",
      "Run time: 0.03900003433227539\n",
      "\n",
      "marathon\n",
      "Type of return <class 'numpy.ndarray'>\n",
      "Shape of return (3072,)\n",
      "Run time: 0.03762507438659668\n",
      "\n",
      "zero\n",
      "Type of return <class 'numpy.ndarray'>\n",
      "Shape of return (3072,)\n",
      "Run time: 0.03663778305053711\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for keyword in ['race','trail','marathon', 'zero']:\n",
    "    print(keyword)\n",
    "    unit_test4(keyword)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47c462b1",
   "metadata": {},
   "source": [
    "When testing the keyword count, we are interested that all the outputs have the correct data types but also that the matchign words in the text fit the keyword acceptably well "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "efd58463",
   "metadata": {},
   "outputs": [],
   "source": [
    "def unit_test5(keyword, article):\n",
    "    start = time.time()\n",
    "    test_count=article_keyword_count(keyword_encode(keyword),article)\n",
    "    end= time.time()\n",
    "    \n",
    "    print('Type of return:',type(test_count))\n",
    "    print('Type of first element:',type(test_count[0]))\n",
    "    print('Type of second element:',type(test_count[1]))\n",
    "    \n",
    "    print('Keywords matched to:',test_count[1].to_list())\n",
    "    print('Run time:',end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "908ae2a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "race\n",
      "Type of return: <class 'tuple'>\n",
      "Type of first element: <class 'int'>\n",
      "Type of second element: <class 'pandas.core.series.Series'>\n",
      "Keywords matched to: ['speed', 'rider', 'run', 'run', 'distance', 'speed', 'runs', 'trainer', 'speed', 'miles']\n",
      "Run time: 0.06927824020385742\n",
      "\n",
      "trail\n",
      "Type of return: <class 'tuple'>\n",
      "Type of first element: <class 'int'>\n",
      "Type of second element: <class 'pandas.core.series.Series'>\n",
      "Keywords matched to: ['form', 'cushion', 'experience', 'confidence', 'heel', 'cup', 'cushion', 'tempo', 'abuse']\n",
      "Run time: 0.056177616119384766\n",
      "\n",
      "marathon\n",
      "Type of return: <class 'tuple'>\n",
      "Type of first element: <class 'int'>\n",
      "Type of second element: <class 'pandas.core.series.Series'>\n",
      "Keywords matched to: ['shoes', 'runners', 'runner', 'glide', 'run', 'mile', 'run', 'distance', 'runs', 'marathon', '##e', 'runners', 'runs', 'running', 'runs', 'runs', 'marathon', 'long', 'runs', 'runner', 'tempo', 'runs', 'workout', 'abuse', 'ran', 'running', 'marathon', 'trainer', 'speed', 'tempo', 'days', 'running', 'miles']\n",
      "Run time: 0.05390119552612305\n",
      "\n",
      "zero\n",
      "Type of return: <class 'tuple'>\n",
      "Type of first element: <class 'int'>\n",
      "Type of second element: <class 'pandas.core.series.Series'>\n",
      "Keywords matched to: ['two', '15']\n",
      "Run time: 0.047136545181274414\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for keyword in ['race','trail','marathon', 'zero']:\n",
    "    print(keyword)\n",
    "    unit_test5(keyword, review_data['encoded_review_body'].iloc[100])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1157bc35",
   "metadata": {},
   "source": [
    "## Keyword Search "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "133dbbd5",
   "metadata": {},
   "source": [
    "This is the final section, where everything comes together into a function that can search for articles in our dataset based on how many words in the article are similar to a keyword. \n",
    "\n",
    "search_keywords does all the significant work here: first encoding the keyword, then searching in all the articles using pandas apply before finding the to n mathces.\n",
    "\n",
    "print_search just presents this information in a nicely readable format "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b5387abf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_keywords(keyword,dataset=review_data.copy(), topn=3):\n",
    "    encoded_keyword=keyword_encode(keyword)\n",
    "    dataset['keyword_count']=dataset['encoded_review_body'].apply(lambda x: article_keyword_count(encoded_keyword,x)[0])\n",
    "    dataset=dataset.nlargest(topn, 'keyword_count')\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ac4e3008",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_search(keyword):\n",
    "    start = time.time()\n",
    "    test_search=search_keywords(keyword)\n",
    "    \n",
    "    \n",
    "    for i in range(3):\n",
    "    \n",
    "        print(test_search['headline'].iloc[i])\n",
    "        print()\n",
    "        print(test_search['description'].iloc[i])\n",
    "        print()\n",
    "        print(test_search['link'].iloc[i])\n",
    "        print('-'*50)\n",
    "        print()\n",
    "    end= time.time()\n",
    "    print(f'Search time: {end-start}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e1b27b72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ON Cloudrunner\n",
      "\n",
      "The newest Cloudrunner is the best one to date. It's stronger than the last one and the realignment of the ringlets in conjunction with the Speedboard make this a very fast shoe for endurance runners. It handles well on the trails, but is not a true trail shoe. It's fun to run with this shoe and it looks great.\n",
      "\n",
      "https://www.runningshoesguru.com/2013/07/on-running-cloudrunner-review/\n",
      "--------------------------------------------------\n",
      "\n",
      "Adidas Adizero Adios Pro\n",
      "\n",
      "The Adidas Adizero Adios Pro is the flagship Adidas racing shoe and is a serious competitor to the Vaporfly and Alphafly Next%.  Its new Lightstrike Pro midsole provides a bouncy, fun ride while its extreme rocker results in a propulsive, forward tipping sensation during every toe-off.  The Adios Pro is a force to be reckoned with and at $50 less than the Vaporfly Next%, it's a steal. \n",
      "\n",
      "https://www.runningshoesguru.com/2020/11/adidas-adizero-adios-pro-review/\n",
      "--------------------------------------------------\n",
      "\n",
      "New Balance FuelCell RC Elite\n",
      "\n",
      "The New Balance FuelCell RC Elite is a highly cushioned racer which excels at the marathon distance.  Its ultra-low density FuelCell midsole combined with its carbon plate result in an efficient ride which is much faster than it feels. \n",
      "\n",
      "https://www.runningshoesguru.com/2020/10/new-balance-fuelcell-rc-elite-review/\n",
      "--------------------------------------------------\n",
      "\n",
      "Search time: 44.028257608413696\n"
     ]
    }
   ],
   "source": [
    "print_search('marathon')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c5da63a",
   "metadata": {},
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f87337f",
   "metadata": {},
   "source": [
    "In this notebook we have built a search algorithm that uses BERT to find articles in the running dataset based on a keyword that we are interested in. Considering that this is an unsupervised task it is difficult to assess how successfuly this has been, but I welcome you to test out different search terms and decide for yourself how well the results match. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "537d0c3c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
